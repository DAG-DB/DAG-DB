2022-09-11 BST 07:31:59,822 - INFO - 
Log for run 2022-09-11_BST_07:31:59,818_sachs_dag_training_lambda_0,01

2022-09-11 BST 07:31:59,822 - INFO - COMMENT = 'IMLE_Logistic_None for Sachs data with DAG traning'
2022-09-11 BST 07:31:59,822 - INFO - DATA_FOLDER = '../data'
2022-09-11 BST 07:31:59,822 - INFO - LATENTS_FOLDER = '../latents'
2022-09-11 BST 07:31:59,822 - INFO - LOGS_FOLDER = '../logs'
2022-09-11 BST 07:31:59,822 - INFO - MODEL_FOLDER = '../models'
2022-09-11 BST 07:31:59,822 - INFO - RESULTS_FOLDER = '../results'
2022-09-11 BST 07:31:59,822 - INFO - DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Used: "cuda"
2022-09-11 BST 07:31:59,822 - INFO - LATENTS = False
2022-09-11 BST 07:31:59,822 - INFO - MATRIX_REPORT = False
2022-09-11 BST 07:31:59,822 - INFO - LABEL = True
2022-09-11 BST 07:31:59,822 - INFO - SAVE_TO_ODS = False
2022-09-11 BST 07:31:59,822 - INFO - VAL_LOSS_FROM_DAG = True
2022-09-11 BST 07:31:59,822 - INFO - WANDB = False
2022-09-11 BST 07:31:59,822 - INFO - WANDB_PROJECT = 'Thetas'
2022-09-11 BST 07:31:59,822 - INFO - GRAD_LOG = False
2022-09-11 BST 07:31:59,822 - INFO - SAVE_RESULTS = True
2022-09-11 BST 07:31:59,822 - INFO - N_TRIALS = 1
2022-09-11 BST 07:31:59,822 - INFO - LOAD_OPTUNA_STUDY = None
2022-09-11 BST 07:31:59,822 - INFO - OPTUNA_STRINGS = {'None': None, 'True': True, 'False': False}
2022-09-11 BST 07:31:59,822 - INFO - TQDM = False
2022-09-11 BST 07:31:59,822 - INFO - 
hyperparameters = {
2022-09-11 BST 07:31:59,822 - INFO - 	'GRAPH_TYPE': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'D': 11,
2022-09-11 BST 07:31:59,822 - INFO - 	'MAX_SIZE': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'SEM_NOISE': 'gaussian_ev',
2022-09-11 BST 07:31:59,822 - INFO - 	'VAL': 0.009378663540445486,
2022-09-11 BST 07:31:59,822 - INFO - 	'N_EPOCHS': 1000,
2022-09-11 BST 07:31:59,822 - INFO - 	'BATCH_SIZE': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'LOG2_BATCH_SIZE': 3,
2022-09-11 BST 07:31:59,822 - INFO - 	'BATCH_SHUFFLE': True,
2022-09-11 BST 07:31:59,822 - INFO - 	'N_SAMPLES': 47,
2022-09-11 BST 07:31:59,822 - INFO - 	'MODE': 'max_dag',
2022-09-11 BST 07:31:59,822 - INFO - 	'AFAS_SCHEDULER': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'MINIZINC_SOLVER': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'f_LINEAR_LAYERS': (),
2022-09-11 BST 07:31:59,822 - INFO - 	'f_BIAS': False,
2022-09-11 BST 07:31:59,822 - INFO - 	'p_LAYER': None,
2022-09-11 BST 07:31:59,822 - INFO - 	'STREAMLINE': False,
2022-09-11 BST 07:31:59,822 - INFO - 	'THRESHOLD': 0.0,
2022-09-11 BST 07:31:59,823 - INFO - 	'h_LINEAR_LAYERS': (),
2022-09-11 BST 07:31:59,823 - INFO - 	'h_NULL': 0.00011373901985660933,
2022-09-11 BST 07:31:59,823 - INFO - 	'h_LR': 0.0016158450337500668,
2022-09-11 BST 07:31:59,823 - INFO - 	'h_OPTIMIZER': 'torch.optim.Adam(overall_net.h_net.parameters(), lr=h.h_LR)',
2022-09-11 BST 07:31:59,823 - INFO - 	'f_LR': 0.3720066380139224,
2022-09-11 BST 07:31:59,823 - INFO - 	'f_OPTIMIZER': 'torch.optim.Adam(overall_net.f_net.parameters(), lr=h.f_LR)',
2022-09-11 BST 07:31:59,823 - INFO - 	'NOISE_TEMPERATURE': 0.8785929148606203,
2022-09-11 BST 07:31:59,823 - INFO - 	'NOISE_DISTRIBUTION': 'LogisticNoiseDistribution()',
2022-09-11 BST 07:31:59,823 - INFO - 	'LAMBDA': 0.01,
2022-09-11 BST 07:31:59,823 - INFO - 	'LOSS_FN': 'torch.nn.MSELoss()',
2022-09-11 BST 07:31:59,823 - INFO - 	'ALPHA': None,
2022-09-11 BST 07:31:59,823 - INFO - 	'BETA': None,
2022-09-11 BST 07:31:59,823 - INFO - 	'REGULARIZER': None,
2022-09-11 BST 07:31:59,823 - INFO - 	'z_RHO': 0.157451211201,
2022-09-11 BST 07:31:59,823 - INFO - 	'z_MU': 0.00120806965197976,
2022-09-11 BST 07:31:59,823 - INFO - 	'z_REGULARIZER': 'NoTearsZRegularizer(h.D, h.z_RHO, h.z_MU, c.DEVICE)',
2022-09-11 BST 07:31:59,823 - INFO - 	'LR_SCHEDULER': None,
2022-09-11 BST 07:31:59,823 - INFO - 	'DATA_CATEGORY': 'real',
2022-09-11 BST 07:31:59,823 - INFO - 	'DAGS': 'Sachs_1',
2022-09-11 BST 07:31:59,823 - INFO - 	'N_REAL_RUNS': 1
2022-09-11 BST 07:31:59,823 - INFO - }

2022-09-11 BST 07:32:00,098 - INFO - 

DAG 0: size_true=17	X.var()=43694.6783
2022-09-11 BST 07:32:12,433 - INFO -  epoch=   1      train_loss=37360.6364      val_loss=23925.8027      best=1      size=  37      nSHD_c=   3.4545      nSHD=   3.3636      prec_c=   0.0541      change_adj_count=0      
2022-09-11 BST 07:32:49,196 - INFO -  epoch=   6      train_loss=73296.9406      val_loss=22113.9766      best=1      size=  49      nSHD_c=   4.1818      nSHD=   3.7273      prec_c=   0.0612      change_adj_count=5      
2022-09-11 BST 07:33:00,697 - INFO -  epoch=   8      train_loss=40591.7417      val_loss=17392.5938      best=1      size=  48      nSHD_c=   4.1818      nSHD=   3.6364      prec_c=   0.0417      change_adj_count=7      
2022-09-11 BST 07:34:43,857 - INFO -  epoch=  26      train_loss=31877.2050      val_loss=15198.8594      best=1      size=  40      nSHD_c=   3.2727      nSHD=   3.1818      prec_c=   0.1500      change_adj_count=23      
2022-09-11 BST 07:38:57,950 - INFO -  epoch=  72      train_loss=45100.7978      val_loss=13174.4834      best=1      size=  27      nSHD_c=   2.3636      nSHD=   2.1818      prec_c=   0.1852      change_adj_count=48      
2022-09-11 BST 07:41:25,096 - INFO -  epoch= 100      train_loss=24475.2753      val_loss=29137.7461      best=0      size=  24      nSHD_c=   2.0909      nSHD=   2.2727      prec_c=   0.3333      change_adj_count=57      
2022-09-11 BST 07:49:44,378 - INFO -  epoch= 200      train_loss=25410.1323      val_loss=30357.1992      best=0      size=  20      nSHD_c=   1.7273      nSHD=   2.0000      prec_c=   0.4500      change_adj_count=69      
2022-09-11 BST 07:57:31,686 - INFO -  epoch= 300      train_loss=21072.7956      val_loss=21076.9844      best=0      size=  16      nSHD_c=   1.3636      nSHD=   1.6364      prec_c=   0.5625      change_adj_count=73      
2022-09-11 BST 08:04:59,642 - INFO -  epoch= 400      train_loss=23662.8543      val_loss=31328.0488      best=0      size=  12      nSHD_c=   1.1818      nSHD=   1.4545      prec_c=   0.6667      change_adj_count=77      
2022-09-11 BST 08:12:17,470 - INFO -  epoch= 500      train_loss=27869.8128      val_loss=31135.3750      best=0      size=  10      nSHD_c=   1.1818      nSHD=   1.4545      prec_c=   0.7000      change_adj_count=85      
2022-09-11 BST 08:19:29,597 - INFO -  epoch= 600      train_loss=18361.0883      val_loss=20207.7988      best=0      size=   9      nSHD_c=   1.0909      nSHD=   1.3636      prec_c=   0.7778      change_adj_count=86      
2022-09-11 BST 08:26:36,217 - INFO -  epoch= 700      train_loss=19763.2425      val_loss=23993.7734      best=0      size=   9      nSHD_c=   1.0909      nSHD=   1.3636      prec_c=   0.7778      change_adj_count=88      
2022-09-11 BST 08:33:39,277 - INFO -  epoch= 800      train_loss=16755.5488      val_loss=27678.5293      best=0      size=   8      nSHD_c=   1.1818      nSHD=   1.4545      prec_c=   0.7500      change_adj_count=91      
2022-09-11 BST 08:40:39,245 - INFO -  epoch= 900      train_loss=21427.8075      val_loss=20668.3145      best=0      size=   8      nSHD_c=   1.1818      nSHD=   1.4545      prec_c=   0.7500      change_adj_count=91      
2022-09-11 BST 08:47:34,721 - INFO -  epoch=1000      train_loss=24027.4390      val_loss=20829.7363      best=0      size=   7      nSHD_c=   1.2727      nSHD=   1.4545      prec_c=   0.7143      change_adj_count=92      
2022-09-11 BST 08:47:34,723 - INFO - Last epoch results saved in sachs_dag_training_lambda_0,01.csv
2022-09-11 BST 08:47:34,723 - INFO - 
last_mean_nshd_c=1.2727
2022-09-11 BST 08:47:34,723 - INFO - 
Time taken 1:15:35 (h:mm:ss)
2022-09-11 BST 08:47:34,723 - INFO - 
End of log for run 2022-09-11_BST_07:31:59,818_sachs_dag_training_lambda_0,01
